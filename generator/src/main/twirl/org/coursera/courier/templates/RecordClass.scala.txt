@(record: org.coursera.courier.generator.twirl.defs.RecordDefinition)
@import java.util.Calendar
@import com.linkedin.data.schema.SchemaToJsonEncoder
@import com.linkedin.data.schema.JsonBuilder
@import org.coursera.courier.generator.twirl.defs._

@record.scalaDoc.map { doc => @doc }
@@Generated(value = Array("@record.scalaType"), comments = "Courier Data Template.", date = "@(Calendar.getInstance().getTime())")
final class @record.scalaType private (private val dataMap: DataMap)
  extends ScalaRecordTemplate(dataMap, @(record.scalaType).SCHEMA) with Product {
  import @(record.scalaType)._

  @* Provide read access to all fields. *@
  @record.fields.map { field =>
    @field.scalaDoc.map { doc => @doc }

    @* TODO(jbetz): Decide on order of fields and decide how to handle optional fields and defaults. Note that decisions here will impact source backward compatibility! *@
    @field.typ match {
      case primitiveField: PrimitiveDefinition => {
        lazy val @(field.name): @(field.scalaType) = @field.wrapIfOption{obtainDirect(@(record.scalaType).Fields.@(field.name), classOf[@(primitiveField.dataType)])}
      }
      case recordField: RecordDefinition => {
        lazy val @(field.name): @(field.scalaTypeFullname) = @field.wrapIfOption{obtainWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(recordField.scalaTypeFullname)])}
      }
      case unionField: UnionDefinition => {
        lazy val @(field.name): @(unionField.scalaTypeFullname) = @field.wrapIfOption{@(unionField.scalaTypeFullname)(dataMap.getDataMap(@(record.scalaType).Fields.@(field.name).getName))}
      }
      case arrayField: ArrayDefinition => {
        lazy val @(field.name): @(field.scalaTypeFullname) = @field.wrapIfOption{obtainWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(arrayField.scalaTypeFullname)])}
      }
      case mapField: MapDefinition => {
        lazy val @(field.name): @(mapField.scalaTypeFullname) = @field.wrapIfOption{obtainWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(mapField.scalaTypeFullname)])}
      }
      case enumField: EnumDefinition => {
        lazy val @(field.name): @(field.scalaTypeFullname) = @field.wrapAndMapIfOption {
            obtainDirect(@(record.scalaType).Fields.@(field.name), classOf[String])
          } { value => @(enumField.enumFullname).fromString(@value) }
      }
      case customField: ClassDefinition => {
        lazy val @(field.name): @(field.scalaTypeFullname) = @field.wrapIfOption{obtainCustomType(@(record.scalaType).Fields.@(field.name), classOf[@(customField.scalaTypeFullname)])}
      }
      case _: Any => { }
    }
  }

  @* Set all fields. Only called during initialization. *@
  private def setFields(@(record.fieldParamDefs)): Unit = {
    @record.fields.map { field =>
      @field.scalaDoc.map { doc => @doc }
      @field.typ match {
        case primitiveField: PrimitiveDefinition => {
          @field.applyIfOption(field.name) { value => putDirect(@(record.scalaType).Fields.@(field.name), classOf[@(primitiveField.dataType)], @primitiveField.maybeBox{@value})}
        }
        case recordField: RecordDefinition => {
          @field.applyIfOption(field.name) { value => putWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(recordField.scalaTypeFullname)], @value)}
        }
        case unionField: UnionDefinition => {
          @field.applyIfOption(field.name) { value => dataMap.put(@(record.scalaType).Fields.@(field.name).getName, @(value).data())}
        }
        case arrayField: ArrayDefinition => {
          @field.applyIfOption(field.name) { value => putWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(arrayField.scalaTypeFullname)], @value)}
        }
        case mapField: MapDefinition => {
          @field.applyIfOption(field.name) { value => putWrapped(@(record.scalaType).Fields.@(field.name), classOf[@(mapField.scalaTypeFullname)], @value)}
        }
        case enumField: EnumDefinition => {
          @field.applyIfOption(field.name) { value => putDirect(@(record.scalaType).Fields.@(field.name), classOf[String], @(value).toString)}
        }
        case customField: ClassDefinition => {
          @* TODO(jbetz): Figure out how to avoid the unsafe .get call in the "field.dataClass.get.dataType" expression. *@
          @field.applyIfOption(field.name) { value => putCustomType(@(record.scalaType).Fields.@(field.name), classOf[@(customField.scalaTypeFullname)], classOf[@(field.dataClass.get.dataType)], @customField.maybeBox{@value})}
        }
        case _: Any => { }
      }
    }
  }

  override val productArity: Int = @(record.fields.size)

  override def productElement(n: Int): Any =
    n match {
      @record.fields.zipWithIndex.map { case (field, i) =>
      case @i => @field.name}
      case _ => throw new IndexOutOfBoundsException(n.toString)
    }

  override val productPrefix: String = "@(record.scalaType)"

  override def canEqual(that: Any): Boolean = that.isInstanceOf[@(record.scalaType)]

  override def hashCode: Int = ScalaRunTime._hashCode(this)

  override def equals(that: Any): Boolean = ScalaRunTime._equals(this, that)

  override def toString: String = ScalaRunTime._toString(this)

  override def copy(): @(record.scalaType) = {
    new @(record.scalaType)(dataMap)
  }

  @if(record.fields.nonEmpty) {
    def copy(@(record.copyFieldParamDefs)): @(record.scalaType) = {
      val dataMap = new DataMap
      val result = new @(record.scalaType)(dataMap)
      result.setFields(@(record.fieldsAsParams))
      dataMap.setReadOnly()
      result
    }
  }
}

object @(record.scalaType) {
  val SCHEMA = DataTemplateUtil.parseSchema(@("\"\"\"" + SchemaToJsonEncoder.schemaToJson(record.schema, JsonBuilder.Pretty.COMPACT) + "\"\"\"")).asInstanceOf[RecordDataSchema]

  @* Register custom types and coercers. *@
  @record.fields.filter(_.customInfo.isDefined).map { field =>
    @defining(field.customInfo.get) { customInfo =>
      Custom.initializeCustomClass(classOf[@(customInfo.customClass.scalaTypeFullname)])
      @customInfo.coercerClass.map { coercer =>
        @(coercer.scalaTypeFullname).registerCoercer()
      }
    }
  }

  @* Generate any contained types as inner classes. *@
  @record.fields.map { field =>
    @field.enclosingClass match {
      case Some(container) if container == record => {
        @field.typ match {
          case enclosedUnion: UnionDefinition => { @UnionClass(enclosedUnion) }
          case enclosedRecord: RecordDefinition => { @RecordClass(enclosedRecord) }
          case _: Any => { ??? }
        }
      }
      case _ => { }
    }
  }

  private object Fields {
    @record.fields.map { field =>
    val @(field.name) = @(record.scalaType).SCHEMA.getField("@(field.pegasusName)")}
  }

  def apply(@(record.fieldParamDefs)): @(record.scalaType) = {
    val dataMap = new DataMap
    val result = new @(record.scalaType)(dataMap)
    result.setFields(@(record.fieldsAsParams))
    dataMap.setReadOnly()
    result
  }

  def apply(dataMap: DataMap, conversion: DataConversion): @(record.scalaType) = {
    new @(record.scalaType)(DataTemplates.makeImmutable(dataMap, SCHEMA, conversion))
  }

  @* TODO(jbetz): The arity-1 case here "works" but is not clean. For arity-1 we should return Option[Arg1Type], and we return Option[(Arg1Type)] which just happens to be correct, but the added parenthesis create a compiler warning. *@
  @record.fields.size match {
    case 0 => {
      def unapply(record: @(record.scalaType)): Boolean = true
    }
    case _ => {
      def unapply(record: @(record.scalaType)): Option[(@(record.fieldsAsTypeParams))] = {
        try {
          Some((@(record.prefixedFieldParams("record."))))
        } catch {
          case cast: TemplateOutputCastException => None
          case notPresent: RequiredFieldNotPresentException => None
        }
      }
    }
  }
}

